{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5967a050",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107/blob/main/session-2/xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e",
   "metadata": {
    "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e"
   },
   "source": [
    "# Practical Exercise (Optional): Create Modern Modular Network \n",
    "\n",
    "In this exercise, you are going to make use of some architecural elements that you learnt, such as residual connection, and separable convolution, and combine them into a building block, and use this building block to construct a modular network. \n",
    "\n",
    "This building block is similar to what [Xception](https://arxiv.org/abs/1610.02357) is using. \n",
    "\n",
    "Here is the simplified view of our network: \n",
    "\n",
    "![xception](https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/iti107/resources/mini_xception.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a",
   "metadata": {
    "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e403eff-1641-4eb6-8b29-56b124e86156",
   "metadata": {
    "id": "5e403eff-1641-4eb6-8b29-56b124e86156"
   },
   "source": [
    "**Exercise 1 - Define the Xception block**\n",
    "\n",
    "Let us the define our xception block first. Here are the steps you will need to do: \n",
    "1. First save the output from previous block (or if this is the first block, then output from previous convolutional/maxpooling layer) and use this as residual to be added later\n",
    "2. Add the 2 [separable convolutional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D) and the MaxPooling layer. For MaxPooling,  use a pool size of 3, and a stride size of 2. Add BatchNormalization after each separable convolutional layer and before the Activation layer.\n",
    "3. Use 1x1 conv to adjust the size and channels of the residual to match the output from MaxPooling layer. To adjust the size, you can specify the stride size of 2. \n",
    "4. To add the the residual with the output from MaxPooling layer, you can use the [`keras.layers.add()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add).\n",
    "5. As recommended by author of ResNet, the residual should be added before the Activation function. \n",
    "\n",
    "Use 'same' padding throughout the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c",
   "metadata": {
    "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c"
   },
   "outputs": [],
   "source": [
    "def xception_block(x, depth): \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: output from the previous block or previous layer, considered as input to this Xception block\n",
    "       it is a tensor of shape (batch, h, w, channels)\n",
    "    depth: number of channels, it is an int value\n",
    "    \"\"\"\n",
    "    \n",
    "    # save input to be used as skip connection\n",
    "    residual = ?\n",
    "    \n",
    "    # add the first separable convolutional 2D layer (as well as the batch normalization and activation layer)\n",
    "    x = ?\n",
    "    \n",
    "    # add the second separable convolutional 2D layer (as well as the batch normalization BUT without activation layer)\n",
    "    x = ?\n",
    "    \n",
    "    # add the maxpooling 2d layer, with stride of 2\n",
    "    x = ?\n",
    "    \n",
    "    # adjust the size and depth using 1x1 convolution to match the output from last maxpooling layer. Use strides=2 to match the output from maxpooling\n",
    "    residual = ?\n",
    "    \n",
    "    # add back the residual to the output from maxpooling layer\n",
    "    x = ?  \n",
    "    \n",
    "    # add the activation layer\n",
    "    x = ?\n",
    "    \n",
    "    return x # Set aside next residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c566012b-eb2f-45cd-a60e-826a7a9de9ea",
   "metadata": {
    "id": "c566012b-eb2f-45cd-a60e-826a7a9de9ea"
   },
   "source": [
    "**Exercise 2: Build the complete network using Xception blocks**\n",
    "\n",
    "We will then build our complete network using the xception block defined in the previous exercise: \n",
    "1. Define the input layer with appropriate shape\n",
    "2. Define a rescaling layer to normalize the input to between (0,1)\n",
    "3. Define the entry blocks that consist of one Conv2D layer with the stride size of 2 and another Conv2D layer with stride size of 1. Remember to add BatchNormalization after each convolutional layer and before Activation layer.\n",
    "4. Add the series of xception blocks, with different depths `[128,256,512,728]`\n",
    "5. Add the last Separable convolutional 2D layer. Remember to add BatchNormalization layer before the Activation layer.\n",
    "6. Add GlobalAveragePooling2D layer before connected to output Dense Layer\n",
    "7. Use Dropout for the dense layer \n",
    "\n",
    "Use 'same' padding throughout the network.  You can refer to the diagram above for the filter size and number of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c",
   "metadata": {
    "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c"
   },
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes): \n",
    "\n",
    "    inputs = ?\n",
    "\n",
    "    # add resclaing \n",
    "    x = ?\n",
    "    \n",
    "    # Entry blocks\n",
    "\n",
    "    ## 1st conv2d with 32 filters and strides = 2 \n",
    "    x = ?\n",
    "    \n",
    "    ## 2nd conv2d with 64 filters and strides = 1\n",
    "    x = ?\n",
    "\n",
    "    # build a series of xception blocks with different depth\n",
    "    for depth in [128, 256, 512, 728]:\n",
    "        x = ?\n",
    "    \n",
    "    # add the last SeparableConv2D layer, together with BatchNorm and Activation layers\n",
    "    x = ?\n",
    "\n",
    "    # add Global Average Pooling layer before connecting to Dense layer \n",
    "    x = ?\n",
    "\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c",
   "metadata": {
    "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c"
   },
   "outputs": [],
   "source": [
    "image_size = (128,128)\n",
    "\n",
    "model = make_model(input_shape= image_size + (3,), num_classes=2)\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20393c0b-8e73-47d7-a371-70c61e58cbde",
   "metadata": {
    "id": "20393c0b-8e73-47d7-a371-70c61e58cbde"
   },
   "source": [
    "### Create train and validation dataset\n",
    "\n",
    "We will go ahead and download the same dataset, and setup the training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131",
   "metadata": {
    "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "dataset_URL = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz'\n",
    "tf.keras.utils.get_file(origin=dataset_URL, extract=True, cache_dir='.')\n",
    "dataset_folder = os.path.join('datasets', 'cats_and_dogs_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78",
   "metadata": {
    "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='binary'\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef",
   "metadata": {
    "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef"
   },
   "source": [
    "Ok, everything is ready. Now we are ready to put our mini-xception network to test and see if perform better than our previous 'traditional' CNN architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d",
   "metadata": {
    "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d"
   },
   "outputs": [],
   "source": [
    "def create_tb_callback(): \n",
    "\n",
    "    import os\n",
    "    \n",
    "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "    def get_run_logdir():    # use a new directory for each run\n",
    "        \n",
    "        import time\n",
    "        \n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "        return os.path.join(root_logdir, run_id)\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    return tb_callback\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"best_checkpoint\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "# compile our model with loss and optimizer \n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_ds, epochs=30, \n",
    "    validation_data=val_ds,\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0985069-c506-479b-a84e-1e2e5d819de8",
   "metadata": {
    "id": "d0985069-c506-479b-a84e-1e2e5d819de8"
   },
   "outputs": [],
   "source": [
    "best_checkpoint = 'best_checkpoint'\n",
    "\n",
    "model.load_weights(best_checkpoint)\n",
    "model.evaluate(val_ds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "xception.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
