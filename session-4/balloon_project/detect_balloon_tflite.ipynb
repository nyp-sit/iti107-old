{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f0a05-8fc8-4c55-9d12-5b93ada21242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48007d-be9d-41ee-ab03-66575ffd9c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09bab20-45f3-402e-bd88-89ef902f0d6a",
   "metadata": {},
   "source": [
    "We are instantiating a model to make use of its pre-process function for images (e.g. resizing, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b7505-fec9-41b8-92a5-8db1c06e8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = '/home/ubuntu/balloon_project/models/ssd_mobilenet_v2_320x320_coco17_tpu-8/run1/pipeline.config'\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "model_config.ssd.num_classes = 1\n",
    "model_config.ssd.freeze_batchnorm = True\n",
    "detection_model = model_builder.build(\n",
    "      model_config=model_config, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec584ec-35eb-471a-926f-d87533d8a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "        path: a file path.\n",
    "\n",
    "    Returns:\n",
    "        uint8 numpy array with shape (sample, img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(img_data))\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (1,im_height, im_width, 3)).astype(np.uint8)\n",
    "    \n",
    "def plot_detections(image_np,\n",
    "                    boxes,\n",
    "                    classes,\n",
    "                    scores,\n",
    "                    category_index,\n",
    "                    figsize=(12, 16),\n",
    "                    image_name=None):\n",
    "    \"\"\"Wrapper function to visualize detections.\n",
    "\n",
    "    Args:\n",
    "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    boxes: a numpy array of shape [N, 4]\n",
    "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
    "      and match the keys in the label map.\n",
    "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
    "      this function assumes that the boxes to be plotted are groundtruth\n",
    "      boxes and plot all boxes as black with no classes or scores.\n",
    "    category_index: a dict containing category dictionaries (each holding\n",
    "      category index `id` and category name `name`) keyed by category indices.\n",
    "    figsize: size for the figure.\n",
    "    image_name: a name for the image file.\n",
    "    \"\"\"\n",
    "    image_np_with_annotations = image_np.copy()\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_annotations,\n",
    "        boxes,\n",
    "        classes,\n",
    "        scores,\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        min_score_thresh=0.5)\n",
    "    plt.figure(figsize=figsize)\n",
    "    if image_name:\n",
    "        plt.imsave(image_name, image_np_with_annotations)\n",
    "    else:\n",
    "        plt.imshow(image_np_with_annotations)\n",
    "        \n",
    "def detect(interpreter, input_tensor):\n",
    "    \"\"\"Run detection on an input image.\n",
    "\n",
    "    Args:\n",
    "        interpreter: tf.lite.Interpreter\n",
    "        input_tensor: A [1, height, width, 3] Tensor of type tf.float32.\n",
    "          Note that height and width can be anything since the image will be\n",
    "          immediately resized according to the needs of the model within this\n",
    "          function.\n",
    "\n",
    "    Returns:\n",
    "        A dict containing 3 Tensors (`detection_boxes`, `detection_classes`,\n",
    "          and `detection_scores`).\n",
    "    \"\"\"\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # We use the original model for pre-processing, since the TFLite model doesn't\n",
    "    # include pre-processing.\n",
    "    preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n",
    "    interpreter.set_tensor(input_details[0]['index'], preprocessed_image.numpy())\n",
    "    interpreter.invoke()\n",
    "\n",
    "    scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    boxes = interpreter.get_tensor(output_details[1]['index'])\n",
    "    count = interpreter.get_tensor(output_details[2]['index'])\n",
    "    classes = interpreter.get_tensor(output_details[3]['index'])\n",
    "    \n",
    "    return boxes, classes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52f625-b221-4a46-8a08-68a8ef33cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'test_samples/sample_balloon.jpeg'\n",
    "test_image_np = load_image_into_numpy_array(test_image_path)\n",
    "\n",
    "tflite_model_path = 'exported_models/ssd_mobilenet_v2_320x320_coco17_tpu-8/tflite/model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "label_id_offset = 1\n",
    "input_tensor = tf.convert_to_tensor(test_image_np, dtype=tf.float32)\n",
    "boxes, classes, scores = detect(interpreter, input_tensor)\n",
    "\n",
    "PATH_TO_LABELS = 'data/label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "plot_detections(\n",
    "    test_image_np[0],\n",
    "    boxes[0],\n",
    "    classes[0].astype(np.uint32) + label_id_offset,\n",
    "    scores[0],\n",
    "    category_index, figsize=(15, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d51206-fc26-449f-a865-ae1c5e80c21d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
