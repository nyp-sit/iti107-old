{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107/blob/main/session-1/convnet_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsq1dYGJvM9h"
   },
   "source": [
    "# Convolutional Filter\n",
    "\n",
    "Welcome to the programming exercise. This is part of the series of exercises to help you understand and apply convolutional neural networks (Convnet or CNN) to different machine learning problems (e.g. computer vision tasks). In this exercise, we are going to see how kernel or convolution filter (one of the key building block in Convnet) is acting as feature detector (such as edge detector, line detector, etc). We use hand-tuned parameters for our filter in the exercise, but in the following labs, we will train the filter to automatically learn the parameters from data.\n",
    "\n",
    "You will learn: \n",
    "- to use the kernel as a feature detector  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZlA7DT2zqE7"
   },
   "source": [
    "Let us download some sample images to be used for experimenting with our hand-crafted filter later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLhNWYd5wTW0"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/nyp-sit/sdaai-iti107/raw/main/session-1/images/black_circle.jpg\n",
    "!wget https://github.com/nyp-sit/sdaai-iti107/raw/main/session-1/images/vertical_horizontal.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "QtAk_Y7avM9i",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvmoulK2vM9j"
   },
   "source": [
    "First we define some convenient functions to plot image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSyHowmjvM9k"
   },
   "outputs": [],
   "source": [
    "# expect an image of shape (X,Y)\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj9RolN6vM9k"
   },
   "source": [
    "In the following, we will construct a vertical edge detector, using a $3\\times3$ filter. \n",
    "The filter will be as follows (see the explanation in the lecture):\n",
    "$$\\begin{bmatrix}\n",
    " -1 & 0 & 1  \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1\n",
    "\\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "N07vbDUDvM9l",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vertical_filter = np.zeros(shape=(3,3), dtype=np.float32)\n",
    "vertical_filter[:,0] = -1.  # set the first column to -1\n",
    "vertical_filter[:,2] = 1.   # set the 3rd column to 1\n",
    "print(vertical_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "we4KcgGRvM9m"
   },
   "source": [
    "Let us visualize the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "T8xW1H99vM9n",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(vertical_filter, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xIN-AllvM9o"
   },
   "source": [
    "Now we want to apply this filter  to our image below. Let's load and visualize our original image. You will see that the image consists of vertical and horizontal lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "ppbJm6q7vM9o",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "img = image.imread('vertical_horizontal.png')\n",
    "plt.imshow(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B96SWDMvM9p"
   },
   "source": [
    "We will now convolve this image with our filter and see the resulting output. \n",
    "Tensorflow provides a function to perform 2d convolution, called `conv2d()`:\n",
    "\n",
    "```\n",
    "tf.nn.conv2d(\n",
    "    input,\n",
    "    filter=None,\n",
    "    strides=None,\n",
    "    padding=None,\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC',\n",
    "    dilations=[1, 1, 1, 1],\n",
    "    name=None,\n",
    "    filters=None\n",
    ")\n",
    "```\n",
    "\n",
    "It is expecting an input tensor of shape ``[batch, in_height, in_width, in_channels]`` and a filter / kernel tensor of shape ```[filter_height, filter_width, in_channels, out_channels]```\n",
    "\n",
    "So we will have to reshape our image and filter to the appropriate number of axis, i.e. as a 4-D tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "v7tEcfeIvM9q",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "height, width, channels = img.shape\n",
    "\n",
    "# here we take average of our RGB channels and treat this as gray scale image with only 1 color channel\n",
    "img = img.mean(axis=2).astype(np.float32)\n",
    "images = img.reshape(1, height, width, 1)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "qz-cvUBUvM9s",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vertical_filters = vertical_filter.reshape(3,3,1,1)\n",
    "outputs = tf.nn.conv2d(images, vertical_filters, strides=1, padding=\"SAME\")\n",
    "print(outputs.shape)\n",
    "\n",
    "# we take the absolute values, so all values falls within 0,255\n",
    "outputs = np.abs(outputs)\n",
    "# we plot the image data at batch=0 and channel=0, our plot_image expects a a shape of (X,Y), i.e. 2 dimensions\n",
    "plot_image(outputs[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXmCb9-zvM9u"
   },
   "source": [
    "Here you can see that a bright line is shown for every vertical edge detected in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjWnedv9vM9u"
   },
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "Construct a horizontal edge detector (filter) and apply it to the image. Plot the resultant image. (Hint: Note the vertical edge detector has vertical column values transitioning from -1 to 1)\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "\n",
    "```\n",
    "horizontal_filter = np.zeros(shape=(3,3), dtype=np.float32)\n",
    "horizontal_filter[0,:] = -1.  # set the first column to -1\n",
    "horizontal_filter[2,:] = 1.   # set the 3rd column to 1\n",
    "print(horizontal_filter)\n",
    "horizontal_filter = horizontal_filter.reshape(3,3,1,1)\n",
    "outputs = tf.nn.conv2d(images, horizontal_filter, strides=1, padding=\"SAME\")\n",
    "print(outputs.shape)\n",
    "outputs = np.abs(outputs)\n",
    "plot_image(outputs[0,:,:,0])\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "UlyK13E1vM9v",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h_OJEhgvM9w"
   },
   "source": [
    "**Exercise 2 (Optional):** \n",
    "\n",
    "[Sobel filter](https://en.wikipedia.org/wiki/Sobel_operator) is commonly used in computer vision for edge detection, creating images emphasising the edge. $G_x$ and $G_y$ are used to detect pixel gradient in the x and y directions respectively, $|G|$ is used to compute absolute gradient magnitude at eah pixel.\n",
    "\n",
    "\n",
    "$$G_x=\\begin{bmatrix}-1 & 0 & 1  \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1\\end{bmatrix}$$\n",
    "\n",
    "$$G_y=\\begin{bmatrix}-1 & -2 & -1  \\\\ 0 & 0 & 0 \\\\ 1 & 2 & 1\\end{bmatrix}$$\n",
    "\n",
    "$$|G|=\\sqrt{G_x^2 + G_y^2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_DRN2SLvM9w"
   },
   "outputs": [],
   "source": [
    "circle_image = image.imread('black_circle.jpg')\n",
    "plt.imshow(circle_image, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.show()\n",
    "print(circle_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oetoqRvvM9x"
   },
   "source": [
    "Construct the two Sobel filters (based on the formula given above) and apply them to the image. Combined the two resultant images to get the final image. Plot the final image.\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "    \n",
    "```\n",
    "gradx_filter = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
    "gradx_filter = gradx_filter.reshape(3,3,1,1)\n",
    "\n",
    "grady_filter = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n",
    "grady_filter = grady_filter.reshape(3,3,1,1)\n",
    "\n",
    "height, width, channels = circle_image.shape\n",
    "\n",
    "# collapse the 3 channels into a single by taking average\n",
    "circle_image = circle_image.mean(axis=2)\n",
    "\n",
    "# reshape to add in additional batch dimension\n",
    "circle_image = circle_image.reshape(1, height, width, 1)\n",
    "\n",
    "    \n",
    "image_x = tf.nn.conv2d(circle_image, gradx_filter, strides=1, padding=\"SAME\")\n",
    "plot_image(image_x[0,:,:,0])\n",
    "\n",
    "image_y = tf.nn.conv2d(circle_image, grady_filter, strides=1, padding=\"SAME\")\n",
    "plot_image(image_x[0,:,:,0])\n",
    "\n",
    "gradient_magnitude = np.sqrt(np.square(image_x[0,:,:,0]) + np.square(image_y[0,:,:,0]))\n",
    "plt.imshow(gradient_magnitude, cmap='gray')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrft_4zDvM9y"
   },
   "outputs": [],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "\n",
    "# define the G_x filter \n",
    "gradx_filter = None\n",
    "\n",
    "# define the G_x filter \n",
    "grady_filter = None\n",
    "\n",
    "# reshape the circle image to appropriate shape suitable for conv2d\n",
    "heigh, width, channels= circle_image.shape\n",
    "\n",
    "# collapse the 3 channels into a single by taking average\n",
    "circle_image = circle_image = circle_image.mean(axis=2)\n",
    "\n",
    "# add in batch and channel dimension\n",
    "circle_image = None \n",
    "\n",
    "# apply the G_x filter on circle_image to obtain a new image, image_x\n",
    "image_x = None \n",
    "\n",
    "# apply the G_y filter on circle_image to obtain a new image, image_y \n",
    "image_y = None \n",
    "\n",
    "\n",
    "# compute combined gradient magnitude, i.e. sqrt(G_x^2 + G_y^2)\n",
    "gradient_magnitude = None\n",
    "\n",
    "\n",
    "plt.imshow(gradient_magnitude, cmap='gray')\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "convnet_filter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
